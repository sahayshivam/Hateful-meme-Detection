{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open ('data/hate_memes_train_merged.json', 'r') as r_file:\n",
    "    my_file = json.load(r_file)\n",
    "\n",
    "ids = []\n",
    "img = []\n",
    "label = []\n",
    "text = []\n",
    "\n",
    "for obj in my_file:\n",
    "    ids.append(obj['id'])\n",
    "    img.append(obj['img'])\n",
    "    label.append(obj['label'])\n",
    "    text.append(obj['text'])\n",
    "\n",
    "df = pd.DataFrame({'id': ids, 'img': img,'label': label,'text':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import vision\n",
    "import os\n",
    "\n",
    "password_file = \"My Project-e17cafef88b1.json\" \n",
    "\n",
    "def get_all(path, password_file=password_file):\n",
    "    \n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = password_file\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    \n",
    "    \n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    ret_label = [label.description for label in labels]\n",
    "    print(ret_label)\n",
    "\n",
    "    \n",
    "    objects = client.object_localization(\n",
    "        image=image).localized_object_annotations\n",
    "    ret_object = [(object_.name, object_.score) for object_ in objects]\n",
    "    print(ret_object)\n",
    "\n",
    "    return {'path': path,'labels': ret_label, 'objects': ret_object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Forehead', 'Chin', 'Jaw', 'Publication', 'Font', 'Adaptation', 'Poster', 'Photo caption', 'Advertising', 'No expression']\n",
      "[('Person', 0.8108208775520325), ('Person', 0.761947751045227), ('Clothing', 0.6507939696311951)]\n",
      "['Facial expression', 'Smile', 'Flash photography', 'Happy', 'Sleeve', 'Gesture', 'Tie', 'Suit', 'Interaction', 'Font']\n",
      "[('Person', 0.8804235458374023), ('Person', 0.8611292243003845), ('Tie', 0.8482465744018555), ('Outerwear', 0.6752802729606628), ('Clothing', 0.5447781682014465)]\n",
      "['Cat', 'White', 'Felidae', 'Carnivore', 'Blue', 'Small to medium-sized cats', 'Whiskers', 'Grey', 'Red', 'Snout']\n",
      "[('Cat', 0.9049119353294373), ('Bowtie', 0.7293491363525391), ('Cat', 0.727033257484436)]\n",
      "['Dog', 'Photograph', 'Light', 'Dog breed', 'Carnivore', 'Black', 'Mammal', 'Companion dog', 'Snout', 'Sporting Group']\n",
      "[('Dog', 0.931591272354126), ('Dog', 0.8330581784248352)]\n",
      "['Musical instrument', 'Font', 'Music', 'Entertainment', 'Event', 'Photo caption', 'Darkness', 'Suit', 'Formal wear', 'Monochrome photography']\n",
      "[('Person', 0.7632495760917664), ('Clothing', 0.557418704032898)]\n",
      "['Shorts', 'Sports uniform', 'World', 'Jersey', 'Gesture', 'Sportswear', 'Player', 'Hat', 'Sports equipment', 'Sneakers']\n",
      "[('Shorts', 0.9330396056175232), ('Shorts', 0.9212886095046997), ('Shorts', 0.9157028198242188), ('Person', 0.8719411492347717), ('Shoe', 0.8680580258369446), ('Person', 0.8604176640510559), ('Person', 0.8593484163284302), ('Shoe', 0.8587496280670166), ('Shorts', 0.8503004908561707), ('Shorts', 0.8370742797851562)]\n",
      "['Ecoregion', 'Masai lion', 'Lion', 'Felidae', 'Big cats', 'Carnivore', 'Grassland', 'Adaptation', 'Mane', 'Plain']\n",
      "[('Lion', 0.9041476845741272), ('Lion', 0.8557738661766052)]\n",
      "['Flash photography', 'Sleeve', 'Gesture', 'Happy', 'Finger', 'Thigh', 'Elbow', 'Street fashion', 'Eyewear', 'Font']\n",
      "[('Person', 0.8154484033584595), ('Bracelet', 0.7217267751693726), ('Top', 0.6721479296684265)]\n",
      "['Dog', 'Carnivore', 'Organism', 'Whiskers', 'Font', 'Fawn', 'Companion dog', 'Happy', 'Dog breed', 'Snout']\n",
      "[('Dog', 0.7552646994590759)]\n",
      "['Hair', 'Photograph', 'Coat', 'Microphone', 'Human', 'Gesture', 'Font', 'Suit', 'News', 'Blazer']\n",
      "[('Person', 0.7917134761810303), ('Person', 0.6438457369804382), ('Person', 0.6250982880592346), ('Necklace', 0.591241717338562)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4fbddd59055c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdicti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'objects'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-489a69c8020d>\u001b[0m in \u001b[0;36mget_all\u001b[0;34m(path, password_file)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Label detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mret_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/cloud/vision_helpers/decorators.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(self, image, max_results, retry, timeout, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcopied_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         response = self.annotate_image(\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         )\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/cloud/vision_helpers/__init__.py\u001b[0m in \u001b[0;36mannotate_image\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         r = self.batch_annotate_images(\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mrequests\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         )\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/cloud/vision_v1/services/image_annotator/client.py\u001b[0m in \u001b[0;36mbatch_annotate_images\u001b[0;34m(self, request, requests, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Done; return the response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    823\u001b[0m                  compression=None):\n\u001b[1;32m    824\u001b[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[0;32m--> 825\u001b[0;31m                                       wait_for_ready, compression)\n\u001b[0m\u001b[1;32m    826\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    811\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m                 ),), self._context)\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadatum\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._interpret_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/tag.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._BatchOperationTag.event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/operation.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.ReceiveInitialMetadataOperation.un_c\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadata\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._metadatum\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(_cls, key, value)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "objects = []\n",
    "paths = []\n",
    "for i in range(8499):\n",
    "    path = \"data/\"+str(df['img'][i])\n",
    "    \n",
    "    dicti = get_all(path=path)\n",
    "    labels.append(dicti['labels'])\n",
    "    objects.append(dicti['objects'])\n",
    "for i in range(8499):\n",
    "    \n",
    "    paths.append(path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for i in range(len(labels)):\n",
    "    path = \"data/\"+str(df['img'][i])\n",
    "    paths.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = []\n",
    "for lb in labels:\n",
    "    if lb in ['Photo caption', 'Photography', 'Font', 'Text', 'Internet meme']:\n",
    "        pass\n",
    "    else:\n",
    "        list_labels.append(lb)\n",
    "labels.append(list_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_objects = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(objects)):\n",
    "    for j in range(len(objects[i])):\n",
    "        if objects[i][j][1]>0:\n",
    "            \n",
    "            list_objects.append(objects[i][j][0])\n",
    "list_objects = set(list_objects)\n",
    "list_objects = list(list_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "14\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "print(len(list_objects))\n",
    "print(len(text[]))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame({'path': paths,'text': text[:10], 'labels': labels[:10], 'objects':list_objects[:10]\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 path                                               text  \\\n",
      "0  data/img/42953.png   its their character not their color that matters   \n",
      "1  data/img/23058.png  don't be afraid to love again everyone is not ...   \n",
      "2  data/img/13894.png                           putting bows on your pet   \n",
      "3  data/img/37408.png  i love everything and everybody! except for sq...   \n",
      "4  data/img/82403.png  everybody loves chocolate chip cookies, even h...   \n",
      "5  data/img/16952.png           go sports! do the thing! win the points!   \n",
      "6  data/img/76932.png     fine you're right. now can we fucking drop it?   \n",
      "7  data/img/70914.png  tattoos are bad for your health i know 5 milli...   \n",
      "8  data/img/02973.png        how long can i run? till the chain tightens   \n",
      "9  data/img/58306.png  what is he hiding? we need to see his tax retu...   \n",
      "\n",
      "                                              labels         objects  \n",
      "0  [Forehead, Chin, Jaw, Publication, Font, Adapt...           Jeans  \n",
      "1  [Facial expression, Smile, Flash photography, ...            Book  \n",
      "2  [Cat, White, Felidae, Carnivore, Blue, Small t...  Luggage & bags  \n",
      "3  [Dog, Photograph, Light, Dog breed, Carnivore,...             Owl  \n",
      "4  [Musical instrument, Font, Music, Entertainmen...          Bottle  \n",
      "5  [Shorts, Sports uniform, World, Jersey, Gestur...           Scarf  \n",
      "6  [Ecoregion, Masai lion, Lion, Felidae, Big cat...          Bowtie  \n",
      "7  [Flash photography, Sleeve, Gesture, Happy, Fi...          Pillow  \n",
      "8  [Dog, Carnivore, Organism, Whiskers, Font, Faw...          Jacket  \n",
      "9  [Hair, Photograph, Coat, Microphone, Human, Ge...      Microphone  \n"
     ]
    }
   ],
   "source": [
    "print(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.merge(my_df, left_on='img', right_on='path')\n",
    "new_df = new_df.rename(columns={'text_x':'text', 'text_y':'ext_text'})\n",
    "new_df.drop('path', axis=1, inplace=True)\n",
    "new_df['objects'] = new_df['objects'].apply(set).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, img, label, text, ext_text, labels, objects]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sohamjain/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def replaceElongated(word):\n",
    "    \"\"\" Replaces an elongated word with its basic form, unless the word exists in the lexicon \"\"\"\n",
    "\n",
    "    repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "    repl = r'\\1\\2\\3'\n",
    "    if wordnet.synsets(word):\n",
    "        return word\n",
    "    repl_word = repeat_regexp.sub(repl, word)\n",
    "    if repl_word != word:      \n",
    "        return replaceElongated(repl_word)\n",
    "    else:       \n",
    "        return repl_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_elong_text'] = df['text'].apply(lambda x: replaceElongated(x))\n",
    "new_df['no_elong_text'] = new_df['text'].apply(lambda x: replaceElongated(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "with open('slang.txt') as file:\n",
    "    slang_map = dict(map(str.strip, line.partition('\\t')[::2])\n",
    "    for line in file if line.strip())\n",
    "\n",
    "slang_words = sorted(slang_map, key=len, reverse=True)\n",
    "regex = re.compile(r\"\\b({})\\b\".format(\"|\".join(map(re.escape, slang_words))))\n",
    "replaceSlang = partial(regex.sub, lambda m: slang_map[m.group(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_slang'] = df['no_elong_text'].apply(lambda x: replaceSlang(x))\n",
    "new_df['no_slang'] = new_df['no_elong_text'].apply(lambda x: replaceSlang(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "1    3050\n",
      "0    3050\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_class_0, count_class_1 = df.label.value_counts()\n",
    "# Divide by class\n",
    "df_class_0 = df[df['label'] == 0]\n",
    "df_class_1 = df[df['label'] == 1]\n",
    "\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.label.value_counts())\n",
    "df_test_under.label.value_counts().plot(kind='bar', title='Count (label)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat([df_test_under, new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sohamjain/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-26add11d4dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtfid2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mX3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfid2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mX33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfid2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mX_label_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX33\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \"\"\"\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1199\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    220\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, classification_report, plot_confusion_matrix, plot_roc_curve\n",
    "nltk.download('stopwords')\n",
    "\n",
    "new_df = df\n",
    "\n",
    "X = new_df[['no_slang','labels', 'objects']]\n",
    "\n",
    "y = np.array(new_df['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "tfid1 = TfidfVectorizer(stop_words=stopwords.words('english'), min_df=25)\n",
    "X1 = tfid1.fit_transform(X_train['no_slang'])\n",
    "X11 = tfid1.transform(X_test['no_slang'])\n",
    "X_text_test = pd.DataFrame(X11.toarray())\n",
    "X_text = pd.DataFrame(X1.toarray())\n",
    "\n",
    "tfid2 = TfidfVectorizer(stop_words=stopwords.words('english'), min_df=25)\n",
    "X3 = tfid2.fit_transform(X_train['labels'].str.join(' '))\n",
    "X33 = tfid2.transform(X_test['labels'].str.join(' '))\n",
    "X_label_test = pd.DataFrame(X33.toarray())\n",
    "X_label = pd.DataFrame(X3.toarray())\n",
    "\n",
    "#tfid3 = CountVectorizer(stop_words=stopwords.words('english'), min_df=25)\n",
    "#X4 = tfid3.fit_transform(X_train['objects'].str.join(' '))\n",
    "#X44 = tfid3.transform(X_test['objects'].str.join(' '))\n",
    "#X_object_test = pd.DataFrame(X44.toarray())\n",
    "#X_object = pd.DataFrame(X4.toarray())\n",
    "\n",
    "X_train = pd.concat([X_text, X_label], axis=1)\n",
    "X_test = pd.concat([X_text_test, X_label_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Bidirectional, LSTM, Embedding\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "max_words = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,), activation='sigmoid'))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop()\n",
    "\n",
    "plot_losses = PlotLosses(plot_interval = 1, evaluate_interval = None)\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, validation_split=0.1, batch_size=32, epochs=100, callbacks=[plot_losses])\n",
    "score, acc=model.evaluate(X_test,y_test)\n",
    "print(\"The test accuracy is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "probs = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "plot_roc_curve(fpr, tpr)\n",
    "print(\"AUC-ROC :\",auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(512, input_shape=(max_words,), activation='sigmoid'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(128, activation='sigmoid'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(32, activation='sigmoid'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2=model2.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=100, callbacks=[plot_losses])\n",
    "score, acc=model2.evaluate(X_test,y_test)\n",
    "print(\"The test accuracy is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model2.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "plot_roc_curve(fpr, tpr)\n",
    "print(\"AUC-ROC :\",auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=500)\n",
    "tokenizer.fit_on_texts(new_df['no_slang'].to_list())\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(1e-4)\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size, 64))\n",
    "model3.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model3.add(Bidirectional(LSTM(32)))\n",
    "model3.add(Dense(64, activation='sigmoid'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(1))\n",
    "model3.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(mode=\"min\", patience=10, restore_best_weights=True)\n",
    "history3=model3.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=100, callbacks=[plot_losses, early_stopping])\n",
    "score, acc=model3.evaluate(X_test,y_test)\n",
    "print(\"The test accuracy is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model3.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "plot_roc_curve(fpr, tpr)\n",
    "print(\"AUC-ROC :\",auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(512, input_shape=(max_words,), activation='sigmoid'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(256, activation='sigmoid'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(128, activation='sigmoid'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(64, activation='sigmoid'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "model4.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4=model4.fit(X_train, y_train, validation_split=0.2, batch_size=16, epochs=100, callbacks=[plot_losses, early_stopping])\n",
    "score, acc=model4.evaluate(X_test,y_test)\n",
    "print(\"The test accuracy is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model4.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "plot_roc_curve(fpr, tpr)\n",
    "print(\"AUC-ROC :\",auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
